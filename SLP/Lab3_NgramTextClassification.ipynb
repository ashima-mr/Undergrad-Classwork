{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIuDTB6XEOWy",
        "outputId": "fc7ec744-8fe8-4ff7-e13f-b8718584a980"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ff1dxKkskgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1aa7b2-c0c8-427b-9d48-85cc0c65e71a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "DkYPwsDxD7NU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "sK_hL6e-Eggt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/MyDrive/SEM7_SLP/sentiment+labelled+sentences.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "    z.extractall('/content/extracted_data')\n",
        "\n",
        "extracted_files = os.listdir('/content/extracted_data')\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpfHtKCEEAXB",
        "outputId": "2811f539-2959-402b-c4bb-797d479d8c6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['__MACOSX', 'sentiment labelled sentences']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_dir = '/content/extracted_data/sentiment labelled sentences'"
      ],
      "metadata": {
        "id": "Ye6rVo94EbJh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for annot_file in os.listdir(sentence_dir):\n",
        "    file_path = os.path.join(sentence_dir, annot_file)\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        sentences = file.readlines()\n",
        "        for sentence in sentences:\n",
        "            parts = sentence.strip().rsplit('\\t', 1)\n",
        "            if len(parts) == 2:  # Ensure there are exactly two parts: sentence and label\n",
        "                sentence_text, sentiment_label = parts\n",
        "                data.append([sentence_text, sentiment_label])"
      ],
      "metadata": {
        "id": "vrX-2ncmEmCl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=['sentence', 'sentiment'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "23D71ls8En6W",
        "outputId": "4caffd66-2106-429f-9257-f0596ebf2f64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence sentiment\n",
              "0  A very, very, very slow-moving, aimless movie ...         0\n",
              "1  Not sure who was more lost - the flat characte...         0\n",
              "2  Attempting artiness with black & white and cle...         0\n",
              "3       Very little music or anything to speak of.           0\n",
              "4  The best scene in the movie was when Gerardo i...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d37f391-618b-4974-a57b-ba49b360ab98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d37f391-618b-4974-a57b-ba49b360ab98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d37f391-618b-4974-a57b-ba49b360ab98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d37f391-618b-4974-a57b-ba49b360ab98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed2ca613-658e-442c-af54-682df8291ad0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed2ca613-658e-442c-af54-682df8291ad0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed2ca613-658e-442c-af54-682df8291ad0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2983,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"I give Wirefly 1 star.I will contact Cingular/AT&T; and inform them of this practice.\",\n          \"This is probably one of the least effective and utterly unoriginal films I have ever seen in my entire life.  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['sentence']\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "oMd2A8WWEpm1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "XdkPbQFvEwpN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Inbuilt Functions"
      ],
      "metadata": {
        "id": "8brte810Gidf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**CountVectorizer()**: Converts text documents into a matrix of token counts"
      ],
      "metadata": {
        "id": "10YN-qCAGO1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_no_ngrams = CountVectorizer()\n",
        "vectorizer_with_ngrams = CountVectorizer(ngram_range=(1, 2)) #includes unigrams and bigrams"
      ],
      "metadata": {
        "id": "Ag0HA0JFFEhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearn.pipeline.Pipeline[('step_name', transformer_or_estimator)**\n",
        "\n",
        "*Pipeline* is an object that sequences a series of data processing steps and a final estimator into a single object.\n",
        "\n",
        "*Transformer/Estimator*: An object that implements fit and optionally transform (for transformers) or predict (for estimators)."
      ],
      "metadata": {
        "id": "BqKXouvnHN59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_no_ngrams = Pipeline([\n",
        "    ('vectorizer', vectorizer_no_ngrams),\n",
        "    ('classifier', MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "vYtmXfHqGe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_with_ngrams = Pipeline([\n",
        "    ('vectorizer', vectorizer_with_ngrams),\n",
        "    ('classifier', MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "LXYWgwCcHxyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_no_ngrams.fit(X_train, y_train)\n",
        "y_pred_no_ngrams = pipeline_no_ngrams.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_no_ngrams))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_no_ngrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSaM7IojH01u",
        "outputId": "d21f4270-1c28-4dde-b7d2-e168349962d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8255555555555556\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83       443\n",
            "           1       0.85      0.79      0.82       457\n",
            "\n",
            "    accuracy                           0.83       900\n",
            "   macro avg       0.83      0.83      0.83       900\n",
            "weighted avg       0.83      0.83      0.83       900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_with_ngrams.fit(X_train, y_train)\n",
        "y_pred_with_ngrams = pipeline_with_ngrams.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_with_ngrams))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_with_ngrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd4znrKWH4N2",
        "outputId": "724b8ed7-35b1-425e-bcf2-4feef42d19fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8388888888888889\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84       443\n",
            "           1       0.86      0.81      0.84       457\n",
            "\n",
            "    accuracy                           0.84       900\n",
            "   macro avg       0.84      0.84      0.84       900\n",
            "weighted avg       0.84      0.84      0.84       900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBSERVATION\n",
        "\n",
        "**Accuracy**: The accuracy improved from 82.56% to 83.89% when including n-grams. This is likely because the n-grams capture additional context from the text, allowing for more accurate predictions rather just induvidual words alone.\n",
        "\n",
        "**Precision**: Precision improved slightly for both classes. This indicates that the n-gram model is better at predicting the correct class for positive instances while maintaining a good precision for negative instances.\n",
        "\n",
        "**Recall**: Increased recall with n-grams shows that model is better a predicting true class instances.\n",
        "\n",
        "**F1-score**: The F1-scores for both classes have improved which suggests a balanced improvement in both precision and recall due to the inclusion of n-grams.\n",
        "\n",
        "Thus overall, the n-grams based approach enhances the model's ability to capture contextual information from the text leading to more accurate and balanced performance"
      ],
      "metadata": {
        "id": "lf17-9imIhvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without use of inbuilt functions"
      ],
      "metadata": {
        "id": "CWnDLKRLKOEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from math import log"
      ],
      "metadata": {
        "id": "V0zOwKNaK3Oa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnigramFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.vocabulary = {}\n",
        "\n",
        "    def fit(self, documents):\n",
        "        all_words = [word for doc in documents for word in doc]\n",
        "        self.vocabulary = {word: idx for idx, word in enumerate(set(all_words))} #enumerate() creates an index (idx) for all ele in set\n",
        "        # {key: value for item in iterable} key: word ; value: idk ; for the (idx, word) pair output by enumerate()\n",
        "\n",
        "    def transform(self, documents):\n",
        "        # Transform documents into unigram vectors\n",
        "        feature_matrix = np.zeros((len(documents), len(self.vocabulary)))\n",
        "        for i, doc in enumerate(documents):\n",
        "            for word in doc:\n",
        "                if word in self.vocabulary:\n",
        "                    feature_matrix[i, self.vocabulary[word]] += 1\n",
        "        return feature_matrix"
      ],
      "metadata": {
        "id": "yV37aM0aJdgx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_extractor = UnigramFeatureExtractor()\n",
        "unigram_extractor.fit(X_train)"
      ],
      "metadata": {
        "id": "93d76JXOKzD2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_unigram = unigram_extractor.transform(X_train)\n",
        "X_test_unigram = unigram_extractor.transform(X_test)"
      ],
      "metadata": {
        "id": "JmdfmehALSv3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokens[i:]** for i in range(self.n)] generates a list of sublists starting from index i:\n",
        "\n",
        "    For i = 0, tokens[i:] gives ['a', 'b', 'c', 'd'].\n",
        "    For i = 1, tokens[i:] gives ['b', 'c', 'd'].\n",
        "    For i = 2, tokens[i:] gives ['c', 'd'].\n",
        "\n",
        "*** (Splat Operator)**: The splat operator * is used to unpack the list of lists into separate arguments. For the example above, it unpacks [['a', 'b', 'c', 'd'], ['b', 'c', 'd'], ['c', 'd']] into three separate lists.\n",
        "\n",
        "**zip(*[...])**: zip takes multiple iterables (lists in this case) and aggregates them into tuples. The * operator ensures that each inner list is passed as a separate argument to zip."
      ],
      "metadata": {
        "id": "YW0-aBxXMIJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NgramFeatureExtractor:\n",
        "    def __init__(self, n=2):\n",
        "        self.n = n\n",
        "        self.vocabulary = {}\n",
        "\n",
        "    def generate_ngrams(self, tokens):\n",
        "        ngrams = zip(*[tokens[i:] for i in range(self.n)])\n",
        "        return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "    def fit(self, documents):\n",
        "        all_ngrams = []\n",
        "        for doc in documents:\n",
        "            tokens = doc.split() if isinstance(doc, str) else doc\n",
        "\n",
        "            unigrams = tokens #must be converted into a list for concatenation\n",
        "            bigrams = self.generate_ngrams(doc) if self.n >= 2 else []\n",
        "            trigrams = self.generate_ngrams(doc) if self.n >= 3 else []\n",
        "            all_ngrams.extend(unigrams + bigrams + trigrams) #.extend() adds items to end of current list\n",
        "\n",
        "        self.vocabulary = {ngram: idx for idx, ngram in enumerate(set(all_ngrams))}\n",
        "\n",
        "    def transform(self, documents):\n",
        "        feature_matrix = np.zeros((len(documents), len(self.vocabulary)))\n",
        "        for i, doc in enumerate(documents):\n",
        "            tokens = doc.split() if isinstance(doc, str) else doc\n",
        "\n",
        "            unigrams = tokens\n",
        "            bigrams = self.generate_ngrams(doc) if self.n >= 2 else []\n",
        "            trigrams = self.generate_ngrams(doc) if self.n >= 3 else []\n",
        "            ngrams = unigrams + bigrams + trigrams\n",
        "            for ngram in ngrams:\n",
        "                if ngram in self.vocabulary:\n",
        "                    feature_matrix[i, self.vocabulary[ngram]] += 1\n",
        "        return feature_matrix"
      ],
      "metadata": {
        "id": "WtVsVQo2LdQE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_extractor = NgramFeatureExtractor(n=3)\n",
        "ngram_extractor.fit(X_train)"
      ],
      "metadata": {
        "id": "CrC6TGWZNRhs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ngram = ngram_extractor.transform(X_train)\n",
        "X_test_ngram = ngram_extractor.transform(X_test)"
      ],
      "metadata": {
        "id": "-HturKEjOVce"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.class_probs = {}\n",
        "        self.feature_probs = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.classes = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_docs = len(y)\n",
        "        self.classes = np.unique(y)\n",
        "        class_counts = defaultdict(lambda: 0)\n",
        "        feature_counts = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "        for i, label in enumerate(y):\n",
        "            class_counts[label] += 1\n",
        "            for j in range(X.shape[1]):\n",
        "                feature_counts[label][j] += X[i, j]\n",
        "\n",
        "        self.class_probs = {cls: count / num_docs for cls, count in class_counts.items()}\n",
        "        for cls in self.classes:\n",
        "            total_features = sum(feature_counts[cls].values())\n",
        "            for feature in feature_counts[cls]:\n",
        "                self.feature_probs[cls][feature] = (feature_counts[cls][feature] + 1) / (total_features + len(self.classes))\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            log_probs = {}\n",
        "            for cls in self.classes:\n",
        "                log_prob = log(self.class_probs[cls])\n",
        "                for j in range(X.shape[1]):\n",
        "                    if X[i, j] > 0:\n",
        "                        log_prob += log(self.feature_probs[cls].get(j, 1 / (len(self.classes) + 1)))\n",
        "                log_probs[cls] = log_prob\n",
        "            predictions.append(max(log_probs, key=log_probs.get))\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "MGag6jaCK_yG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = NaiveBayesClassifier()\n",
        "nb.fit(X_train_unigram, y_train)\n",
        "y_pred_no_ngrams = nb.predict(X_test_unigram)"
      ],
      "metadata": {
        "id": "-xiz7C4nYTtb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = NaiveBayesClassifier()\n",
        "nb.fit(X_train_ngram, y_train)\n",
        "y_pred_ngrams = nb.predict(X_test_ngram)"
      ],
      "metadata": {
        "id": "t40RFfXOYxG-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_no_ngrams))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_no_ngrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9bL_4onY4pG",
        "outputId": "9d3e52b5-756d-4ba7-c8d5-4b03457f4bea"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6033333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.67      0.62       443\n",
            "           1       0.63      0.54      0.58       457\n",
            "\n",
            "    accuracy                           0.60       900\n",
            "   macro avg       0.61      0.60      0.60       900\n",
            "weighted avg       0.61      0.60      0.60       900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ngrams))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ngrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1ORdyNLZF9n",
        "outputId": "3b679b0d-ef5f-42ec-8f7f-55654adedc44"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8122222222222222\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.81       443\n",
            "           1       0.83      0.79      0.81       457\n",
            "\n",
            "    accuracy                           0.81       900\n",
            "   macro avg       0.81      0.81      0.81       900\n",
            "weighted avg       0.81      0.81      0.81       900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBSERVATION\n",
        "\n",
        "There is a significant impovement in accuracy from the model without n-grams to the model with n-grams, from 60.3% to 81.2%. All other metrics including recall, precision and f1-score also have similar significant increases which indicates that incorporating n-grams helps **capture contextual word relationships more effectively**, leading to better classification performance."
      ],
      "metadata": {
        "id": "UQE3t8NKMdN-"
      }
    }
  ]
}
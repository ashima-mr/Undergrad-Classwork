{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "JcHMaJJLRdmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1bs3AikQwxX",
        "outputId": "138ae902-598d-4fb5-9032-0fe14e19f9f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "aZGDfqoGQ009"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/MyDrive/SEM7_SLP/sentiment+labelled+sentences.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "    z.extractall('/content/extracted_data')\n",
        "\n",
        "extracted_files = os.listdir('/content/extracted_data')\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCHzFclAQ-lb",
        "outputId": "158c7a62-d1dc-41db-d0de-e38dcdba2f5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['sentiment labelled sentences', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_dir = '/content/extracted_data/sentiment labelled sentences'"
      ],
      "metadata": {
        "id": "rinhddc8Q_QT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for annot_file in os.listdir(sentence_dir):\n",
        "    file_path = os.path.join(sentence_dir, annot_file)\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        sentences = file.readlines()\n",
        "        for sentence in sentences:\n",
        "            parts = sentence.strip().rsplit('\\t', 1)\n",
        "            if len(parts) == 2:  # Ensure there are exactly two parts: sentence and label\n",
        "                sentence_text, sentiment_label = parts\n",
        "                data.append([sentence_text, sentiment_label])"
      ],
      "metadata": {
        "id": "7TZKSECiRCLb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=['sentence', 'sentiment'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ziuV9OVcREOS",
        "outputId": "c9c19193-df05-4423-b5d3-02dc7d3913d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence sentiment\n",
              "0  A very, very, very slow-moving, aimless movie ...         0\n",
              "1  Not sure who was more lost - the flat characte...         0\n",
              "2  Attempting artiness with black & white and cle...         0\n",
              "3       Very little music or anything to speak of.           0\n",
              "4  The best scene in the movie was when Gerardo i...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0f1d3cb-b66f-4f4a-9a33-3f986f7199d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0f1d3cb-b66f-4f4a-9a33-3f986f7199d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0f1d3cb-b66f-4f4a-9a33-3f986f7199d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0f1d3cb-b66f-4f4a-9a33-3f986f7199d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27d428c1-e472-44b9-875d-a86a9e1ec351\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27d428c1-e472-44b9-875d-a86a9e1ec351')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27d428c1-e472-44b9-875d-a86a9e1ec351 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2983,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"I give Wirefly 1 star.I will contact Cingular/AT&T; and inform them of this practice.\",\n          \"This is probably one of the least effective and utterly unoriginal films I have ever seen in my entire life.  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "BxX-xUgSRh_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "3ctLdjlvRFtF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyzt5xCHRpL3",
        "outputId": "7ad3e122-45c4-4250-c116-03fead046648"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) #create a set from the stopwords module of nltk for enlish stopwords"
      ],
      "metadata": {
        "id": "QOATPv38RrSI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "KJsTG513SNIu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['processed_text'] = df['sentence'].apply(preprocess)"
      ],
      "metadata": {
        "id": "-MjM-waJSPvG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With In-built Functions"
      ],
      "metadata": {
        "id": "En2MUH1kHlh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression #can't use NB bc word2vec vectors can have negetive values while NB does not accept -ve values\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "1Zb4VtDjHtCX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['processed_text']\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "6IOG8PaSHXmI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "kBbmj_DFHe9A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector Space Model: TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "OxbRqI0tHhzo",
        "outputId": "d10279c3-202c-419b-9d71-f4b5afa4e7a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_tfidf = LogisticRegression(max_iter=1000)\n",
        "clf_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(f'TF-IDF Accuracy: {accuracy_tfidf:.4f}')"
      ],
      "metadata": {
        "id": "Y4bdtBz3a-VV",
        "outputId": "3b9e3ce7-c476-4b2e-92c7-1b7421238e4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Accuracy: 0.7911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embeddings: Word2Vec\n",
        "model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "c186fu53bxOx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gensim Library's Word2Vec Model**\n",
        "\n",
        "**vector_size=100**: The dimensionality of the word vectors. Each word will be represented as a 100-dimensional vector.\n",
        "\n",
        "**window=5**: The maximum distance between the current and predicted word within a sentence. This parameter affects how many surrounding words are considered for context.\n",
        "\n",
        "**min_count=1**: Ignores all words with a total frequency lower than this. In this case, all words are included since min_count is set to 1.\n",
        "\n",
        "**workers=4**: Number of worker threads used to train the model."
      ],
      "metadata": {
        "id": "Tpcfn6YLct0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec model generates dense word vectors (embeddings) for each word. The **vectorize_text function** averages the vectors of the words in a document. This approach aggregates word-level information into a document-level representation, which can then be used for various machine learning tasks.\n",
        "\n",
        "**model.wv**\n",
        "model: This is an instance of the Word2Vec class after training.\n",
        "wv: Stands for \"word vectors\". It is an attribute of the trained Word2Vec model that provides access to the vectors for the words in the vocabulary."
      ],
      "metadata": {
        "id": "DF72tTetdlvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, model):\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in text:\n",
        "        if word in model.wv:\n",
        "            vector += model.wv[word]\n",
        "            count += 1\n",
        "    return vector / count if count != 0 else vector"
      ],
      "metadata": {
        "id": "sDilDSS5cQqd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v = np.array([vectorize_text(text, model) for text in X_train])\n",
        "X_test_w2v = np.array([vectorize_text(text, model) for text in X_test])"
      ],
      "metadata": {
        "id": "ESKTH9JNeX8j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_w2v = LogisticRegression(max_iter=1000)\n",
        "clf_w2v.fit(X_train_w2v, y_train)\n",
        "y_pred_w2v = clf_w2v.predict(X_test_w2v)\n",
        "accuracy_w2v = accuracy_score(y_test, y_pred_w2v)\n",
        "print(f'Word2Vec Accuracy: {accuracy_w2v:.4f}')"
      ],
      "metadata": {
        "id": "yilRD3yWefJB",
        "outputId": "347282d6-c70c-4216-9f54-66508080d0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec Accuracy: 0.5644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBSERVATION\n",
        "\n",
        "The TF-IDF accuracy is significantly higher than the Word2Vec accuracy at 79.1% and 56.4%. Possible reasons for this output may be due to my choice of classifier being Logistic Regression for which the sparse, count-based nature of TF-IDF vectors provides clear and distinct features that it can leverage to differentiate between classes, resulting in relatively higher accuracy. On the other hand, Word2Vec's dense, continuous vectors while capture semantic relationships and contextual information, include negative values and are aggregated into document vectors by averaging. This aggregation can lead to a loss of individual word-specific features and nuances that reduce the distinction of indivdual features leading to an overall lower accuracy.\n"
      ],
      "metadata": {
        "id": "4gFe05DufRgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without In-built Functions"
      ],
      "metadata": {
        "id": "ZnqDv1IQgrgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import math"
      ],
      "metadata": {
        "id": "E0kDpRTqguKX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**df = defaultdict(int)** is used to create a dictionary where missing keys automatically get a default value. Here's a detailed explanation of what this line does:"
      ],
      "metadata": {
        "id": "sJ-M9YgrhRHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TF_IDF:\n",
        "    def __init__(self):\n",
        "        self.vocabulary = {}\n",
        "        self.idf = {}\n",
        "\n",
        "    def fit(self, documents):\n",
        "        df = defaultdict(int)\n",
        "        for doc in documents:\n",
        "            unique_terms = set(doc)\n",
        "            for term in unique_terms:\n",
        "                df[term] += 1\n",
        "        self.vocabulary = {term: idx for idx, term in enumerate(df.keys())}\n",
        "        total_docs = len(documents)\n",
        "        self.idf = {term: math.log((total_docs + 1) / (df_count + 1)) + 1 for term, df_count in df.items()}\n",
        "\n",
        "    def transform(self, documents):\n",
        "        tfidf_matrix = np.zeros((len(documents), len(self.vocabulary)))\n",
        "        for i, doc in enumerate(documents):\n",
        "            tf = defaultdict(int)\n",
        "            for term in doc:\n",
        "                if term in self.vocabulary:\n",
        "                    tf[term] += 1\n",
        "            doc_len = len(doc)\n",
        "            for term, count in tf.items():\n",
        "                if term in self.vocabulary:\n",
        "                    tf_val = count / doc_len\n",
        "                    tfidf = tf_val * self.idf.get(term, 0.0)\n",
        "                    tfidf_matrix[i, self.vocabulary[term]] = tfidf\n",
        "        return tfidf_matrix"
      ],
      "metadata": {
        "id": "BN0QhmRKg_7A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TF_IDF()\n",
        "tfidf.fit(X_train)"
      ],
      "metadata": {
        "id": "M8Xzs8z8hY9i"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf = tfidf.transform(X_train)"
      ],
      "metadata": {
        "id": "C_wRdkC-kjta"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "425CF81Dh4af"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000, verbose=False):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self.sigmoid(linear_model)\n",
        "\n",
        "            dw = np.dot(X.T, (y_pred - y)) / len(y)\n",
        "            db = np.sum(y_pred - y) / len(y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "            if self.verbose and epoch % 100 == 0:\n",
        "                loss = - (y * np.log(y_pred + 1e-15) + (1 - y) * np.log(1 - y_pred + 1e-15)).mean()\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        return self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return (self.predict_prob(X) >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "OyPOueLsiuGo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf= LogisticRegression()\n",
        "clf.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "1J5K3uDsjlBQ",
        "outputId": "849ccfcb-288b-4d44-ac29-995047027885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= clf.predict(X_test_tfidf)\n",
        "accuracy= accuracy_score(y_test, y_pred)\n",
        "print(f'TF-IDF Accuracy: {accuracy_tfidf:.4f}')"
      ],
      "metadata": {
        "id": "IQMe9BXIj6a4",
        "outputId": "778cdc91-eab7-4aba-d177-fb7150acbadb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Accuracy: 0.7911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBSERVATION\n",
        "\n",
        "Manual implementation of TF-IDF proves the same as previously."
      ],
      "metadata": {
        "id": "4QXC8y4WldQE"
      }
    }
  ]
}